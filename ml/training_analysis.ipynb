{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb7c87f-f1d4-4a3f-a618-8639bb423b6e",
   "metadata": {},
   "source": [
    "# Titanic Machine Learning Competition\n",
    "\n",
    "## Model Creating, Training & Testing\n",
    "- In this notebook we will create a ML model to predict which passengers survive the Titanic.\n",
    "  - I will create 2 different models:\n",
    "    - A Neural Network (Dense)\n",
    "    - RandomForestClassifier\n",
    "  - I'll compare both models and pick the one that performs best\n",
    "- We will also be training and testing the model to ensure predictions are accurate.\n",
    "- Finally, I will create plots for visualizing and analyzing overfitting vs underfitting, as well as predictions vs actuals with the chosen threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1cb6fc-17cb-4ab8-9765-94ef173a2518",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "- Lets start by importing the modules we will be utilizing in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "ff2ac39d-efdb-4142-a9f9-5bf14040a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92176845-0eb2-4839-9182-3ab23f689441",
   "metadata": {},
   "source": [
    "## Dataset Load\n",
    "- Lets go ahead and import the train.csv into a pandas dataframe which we will be utilizing through the notebook\n",
    "- Lets also create our X (features) and y(actual answers) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "92955275-9aa5-4243-bb72-8a37eaa8e71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../titanic_data/train.csv\")\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Create feature and answer dataset\n",
    "cols = df.columns\n",
    "X = df #Do not remove passengerId or Survived columns yet\n",
    "y = df[[col for col in df.columns if col in (\"PassengerId\", \"Survived\")]]\n",
    "\n",
    "X.head(10)\n",
    "#y.head(10) # uncomment if need to see results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dc35b-9f44-4d7c-8a49-fe15b46db00b",
   "metadata": {},
   "source": [
    "## Feature Engineering - Part 1\n",
    "- Lets go ahead and add 2 of our 4 data engineer features we created in the dataset_analysis notebook. We will add the other 2 later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "7452f1fd-2d4c-4d04-8903-14ae2df6a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>class_group</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Lower</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Middle</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked class_group age_group  \n",
       "0      0         A/5 21171   7.2500   NaN        S       Lower     young  \n",
       "1      0          PC 17599  71.2833   C85        C       Upper    middle  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       Lower     young  \n",
       "3      0            113803  53.1000  C123        S       Upper    middle  \n",
       "4      0            373450   8.0500   NaN        S       Lower    middle  \n",
       "5      0            330877   8.4583   NaN        Q       Lower       NaN  \n",
       "6      0             17463  51.8625   E46        S       Upper    middle  \n",
       "7      1            349909  21.0750   NaN        S       Lower     young  \n",
       "8      2            347742  11.1333   NaN        S       Lower     young  \n",
       "9      0            237736  30.0708   NaN        C      Middle     young  "
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the class_group and the age_group engineered feature.\n",
    "X[\"class_group\"] = X.Pclass.map({1: \"Upper\", 2: \"Middle\", 3: \"Lower\"})\n",
    "X[\"age_group\"] = pd.cut(X.Age, bins=[-np.inf, 30, 60, np.inf], labels=[\"young\", \"middle\", \"old\"], right=True)\n",
    "\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870dc6c-7c38-4c4c-803b-d355d057c2ed",
   "metadata": {},
   "source": [
    "## Dataset Cleanup\n",
    "- Lets now cleanse our dataset.\n",
    "- We need to populate all rows for all columns that do not have a value (NaNs)\n",
    "- Based on observations made on the dataset_analysis notebook, the columns with NaNs in them are: Age, Cabin and Embarked.\n",
    "- We will start with Embarked, Age and then Cabin. And we will implement the same logic we implemented in the dataset_analysis notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0647b-6c92-4e96-83bb-5e7b87483021",
   "metadata": {},
   "source": [
    "## NaN Embarked\n",
    "- Now lets replace all NaN for Embarked column with an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "2a6befa0-8fc9-4441-a757-84e409e8dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "class_group      0\n",
      "age_group      177\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lets fill Embarked utilizing the avg passenger observed by class and gender \n",
    "embarked_by_class_gender = ( \n",
    "    df.groupby([\"class_group\", \"Sex\", \"Embarked\"], observed=True)\n",
    "    .size() \n",
    "    .reset_index(name='n') \n",
    ") \n",
    "\n",
    "top_embarkments = ( \n",
    "    embarked_by_class_gender \n",
    "    .sort_values([\"class_group\", \"Sex\", \"n\", \"Embarked\"], ascending=[True, True, False, True]) \n",
    "    .drop_duplicates(subset=[\"class_group\", \"Sex\"], keep=\"first\") \n",
    "    .rename(columns={'Embarked': 'top_embarked', 'n': 'top_count'})\n",
    "    .reset_index(drop=True) \n",
    ") \n",
    "\n",
    "X = X.merge(top_embarkments, on=[\"class_group\", \"Sex\"], how=\"left\") \n",
    "X.Embarked = X.Embarked.fillna(X.top_embarked) \n",
    "X.drop(columns=[\"top_count\", \"top_embarked\"], inplace=True) \n",
    "\n",
    "print(X.isna().sum()) # Embarked should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b9863-ad61-454e-a92b-7136281e684c",
   "metadata": {},
   "source": [
    "## NaN Age\n",
    "- Now lets replace all NaN for Age column with an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "19b26d42-5ac8-4f8f-ac50-f4410a4229ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "class_group      0\n",
      "age_group        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lets fill Age utilizing the top age  observed by class, gender, and embarkment \n",
    "age_by_class_gender = ( \n",
    "    X.groupby([\"class_group\", \"Sex\", \"Embarked\", \"Age\"], observed=True)\n",
    "    .size()\n",
    "    .reset_index(name='n') \n",
    ") \n",
    "\n",
    "# Extract only top records per group\n",
    "top_ages = ( \n",
    "    age_by_class_gender\n",
    "    .sort_values([\"class_group\", \"Sex\", \"Embarked\", \"Age\", \"n\"], ascending=[True, True, True, True, False]) \n",
    "    .drop_duplicates(subset=[\"class_group\", \"Sex\", \"Embarked\"], keep=\"first\") \n",
    "    .rename(columns={\"Age\": \"top_age\", \"n\": \"top_count\"}) \n",
    "    .reset_index(drop=True) \n",
    ") \n",
    "\n",
    "# Fill all NaNs for Age\n",
    "X = X.merge(top_ages, on=[\"class_group\", \"Sex\", \"Embarked\"], how=\"left\") \n",
    "X.Age = X.Age.fillna(X.top_age) \n",
    "X.drop(columns=[\"top_count\", \"top_age\"], inplace=True) \n",
    "\n",
    "# Lets reapply the Age bins to remove NaNs from age_group as well \n",
    "X[\"age_group\"] = pd.cut( \n",
    "    X.Age, \n",
    "    bins = [-np.inf, 30, 60, np.inf], \n",
    "    labels = [\"young\", \"middle\", \"old\"], \n",
    "    right=True\n",
    ") \n",
    "\n",
    "print(X.isna().sum()) # Age and age_group should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183f8a4-4842-4706-bb6e-36de3a0198d3",
   "metadata": {},
   "source": [
    "## NaN Cabin\n",
    "- Now lets replace all NaN for the Cabin column with an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "fb538da4-157b-4e4a-b11a-c8b42ce3eed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "class_group    0\n",
      "age_group      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The assignment of a cabin to a passenger was most likely affected by the passenger's socio-economic class and age\n",
    "# Lets try to find a pattern, lets look group cabin by socio-economic class, we will only use the first letter of the cabin\n",
    "X.Cabin = X.Cabin.str.strip().str[0]\n",
    "\n",
    "#Lets extract passangers top Cabin, grouped by socio-economic class, age group and sex\n",
    "cabin_by_class = (\n",
    "    X.groupby([\"class_group\", \"age_group\", \"Sex\", \"Cabin\"], observed=True, dropna=False)\n",
    "    .size()\n",
    "    .reset_index(name='n')\n",
    ")\n",
    "\n",
    "keys = ['class_group', 'age_group', 'Sex']\n",
    "valid_cabins = cabin_by_class[cabin_by_class['Cabin'].notna()].copy()\n",
    "\n",
    "# Extract top Cabins per group\n",
    "top_cabins_per_group = (\n",
    "    valid_cabins\n",
    "      .sort_values(keys + ['n', 'Cabin'], ascending=[True, True, True, False, True])\n",
    "      .drop_duplicates(subset=keys, keep='first')\n",
    "      .rename(columns={'Cabin': 'top_cabin', 'n': 'top_count'})\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Fall back in case not all NaNs are filled by top_cabins_per_group\n",
    "top_cabin_per_class = (\n",
    "    valid_cabins\n",
    "    .sort_values(\"class_group\", ascending=[True])\n",
    "    .drop_duplicates(subset=[\"class_group\"], keep=\"first\")\n",
    "    .rename(columns={'Cabin': 'top_cabin', 'n': 'top_count'})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Fill NaN Cabin with the group's most common cabin\n",
    "X = X.merge(top_cabins_per_group[['class_group', 'age_group', 'Sex', 'top_cabin']], on=keys, how='left')\n",
    "X['Cabin'] = X['Cabin'].fillna(X['top_cabin'])\n",
    "X.drop(columns=[\"top_cabin\"], errors='ignore', inplace=True)\n",
    "\n",
    "# Fallback in case there are still NaNs for Cabins\n",
    "if X.Cabin.isna().sum() > 0:\n",
    "    cabin_by_class = (\n",
    "        X.groupby([\"class_group\", \"Cabin\"], observed=True, dropna=True)\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "    )\n",
    "    \n",
    "    X = X.merge(top_cabin_per_class[['class_group', 'top_cabin']], on='class_group', how='left')\n",
    "    X['Cabin'] = X['Cabin'].fillna(X['top_cabin'])\n",
    "\n",
    "X.drop(columns=[\"top_cabin\"], errors='ignore', inplace=True)\n",
    "\n",
    "print(X.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9752e-c358-40b8-b46a-de2f163a569f",
   "metadata": {},
   "source": [
    "## Train & Val Dataset\n",
    "- Now lets create the train and val dataset that will be fed to the model.\n",
    "- For the train dataset, we will add the new 4 features we engineered in the eda notebook.\n",
    "- We will one-hot encode categorical columns and eliminate columns that I believe are not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "0a8a1f4f-2207-4f66-b168-e88b6868aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 14)\n",
      "(534, 26)\n",
      "(357, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>survival_rate</th>\n",
       "      <th>group_size</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>...</th>\n",
       "      <th>port_C</th>\n",
       "      <th>port_Q</th>\n",
       "      <th>port_S</th>\n",
       "      <th>class_Lower</th>\n",
       "      <th>class_Middle</th>\n",
       "      <th>class_Upper</th>\n",
       "      <th>age_young</th>\n",
       "      <th>age_middle</th>\n",
       "      <th>age_old</th>\n",
       "      <th>Deck_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81.8583</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.9000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4750</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.7500</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass   Age  SibSp  Parch      Fare  survival_rate  group_size  Deck_A  \\\n",
       "0        3   1.0      0      0    8.0500       0.142857         161       0   \n",
       "1        3   7.0      4      1   29.1250       0.142857         161       0   \n",
       "2        1  24.0      0      0   49.5042       1.000000          28       0   \n",
       "3        3  18.0      1      0    6.4958       0.142857         161       0   \n",
       "4        1  44.0      0      0   27.7208       0.954545          22       0   \n",
       "5        1  11.0      1      2  120.0000       0.344828          29       0   \n",
       "6        1   4.0      0      2   81.8583       0.344828          29       1   \n",
       "7        1  39.0      1      0   55.9000       0.954545          22       0   \n",
       "8        2  19.0      0      0   13.0000       0.250000          28       0   \n",
       "9        3  61.0      0      0    6.2375       0.000000           2       0   \n",
       "10       3  26.0      1      2   20.5750       0.142857         161       0   \n",
       "11       1  22.0      0      0  135.6333       0.344828          29       0   \n",
       "12       1  43.0      0      1  211.3375       0.954545          22       0   \n",
       "13       3  40.0      1      0    9.4750       0.444444           9       0   \n",
       "14       3  18.0      0      0    8.0500       0.142857         161       0   \n",
       "15       3  17.0      0      0    8.6625       0.142857         161       0   \n",
       "16       2  40.0      0      0   15.7500       0.904762          21       0   \n",
       "17       1  17.0      0      0   27.7208       0.344828          29       0   \n",
       "18       1  35.0      0      0  512.3292       0.400000          35       0   \n",
       "19       3   3.0      1      1   15.9000       0.142857         161       0   \n",
       "\n",
       "    Deck_B  Deck_C  ...  port_C  port_Q  port_S  class_Lower  class_Middle  \\\n",
       "0        0       0  ...       0       0       1            1             0   \n",
       "1        0       0  ...       0       1       0            1             0   \n",
       "2        0       1  ...       1       0       0            0             0   \n",
       "3        0       0  ...       0       0       1            1             0   \n",
       "4        1       0  ...       1       0       0            0             0   \n",
       "5        1       0  ...       0       0       1            0             0   \n",
       "6        0       0  ...       0       0       1            0             0   \n",
       "7        0       0  ...       0       0       1            0             0   \n",
       "8        0       0  ...       0       0       1            0             1   \n",
       "9        0       0  ...       0       0       1            1             0   \n",
       "10       0       0  ...       0       0       1            1             0   \n",
       "11       0       1  ...       1       0       0            0             0   \n",
       "12       1       0  ...       0       0       1            0             0   \n",
       "13       0       0  ...       0       0       1            1             0   \n",
       "14       0       0  ...       0       0       1            1             0   \n",
       "15       0       0  ...       0       0       1            1             0   \n",
       "16       0       0  ...       0       0       1            0             1   \n",
       "17       0       1  ...       1       0       0            0             0   \n",
       "18       1       0  ...       1       0       0            0             0   \n",
       "19       0       0  ...       0       0       1            1             0   \n",
       "\n",
       "    class_Upper  age_young  age_middle  age_old  Deck_T  \n",
       "0             0          1           0        0       0  \n",
       "1             0          1           0        0       0  \n",
       "2             1          1           0        0       0  \n",
       "3             0          1           0        0       0  \n",
       "4             1          0           1        0       0  \n",
       "5             1          1           0        0       0  \n",
       "6             1          1           0        0       0  \n",
       "7             1          0           1        0       0  \n",
       "8             0          1           0        0       0  \n",
       "9             0          0           0        1       0  \n",
       "10            0          1           0        0       0  \n",
       "11            1          1           0        0       0  \n",
       "12            1          0           1        0       0  \n",
       "13            0          0           1        0       0  \n",
       "14            0          1           0        0       0  \n",
       "15            0          1           0        0       0  \n",
       "16            0          0           1        0       0  \n",
       "17            1          1           0        0       0  \n",
       "18            1          0           1        0       0  \n",
       "19            0          1           0        0       0  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset into Train & Val datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.40, train_size=0.60, shuffle=True)\n",
    "\n",
    "# Create survival rate and group_size for train only\n",
    "# At the end, I did not use survival_rate as I believe this is data leakage since I'm using the label to generate this feature\n",
    "X_train_copy = (\n",
    "    X_train.groupby([\"class_group\", \"Sex\", \"age_group\"], observed=False)\n",
    "    .agg(survival_rate=('Survived', 'mean'), group_size=('Survived', 'size'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_train = X_train.merge(X_train_copy, on=[\"class_group\", \"Sex\", \"age_group\"], how=\"left\")\n",
    "\n",
    "# Add metrics observed from each group in the train dataset to the Val dataset\n",
    "X_val = X_val.merge(X_train_copy, on=[\"class_group\", \"Sex\", \"age_group\"], how=\"left\")\n",
    "\n",
    "\n",
    "# Lets create some one-hot encoding for some columns for train_dataset \n",
    "deck = pd.get_dummies(X_train.Cabin.str.strip().str[0], prefix=\"Deck\", dummy_na=True, dtype=\"uint8\")\n",
    "sex = pd.get_dummies(X_train.Sex, prefix=\"Sex\", dummy_na=True, dtype=\"uint8\")\n",
    "port = pd.get_dummies(X_train.Embarked, prefix=\"port\", dummy_na=True, dtype=\"uint8\")\n",
    "class_group = pd.get_dummies(X_train.class_group, prefix=\"class\", dummy_na=True, dtype=\"uint8\")\n",
    "age_group = pd.get_dummies(X_train.age_group, prefix=\"age\", dummy_na=True, dtype=\"uint8\")\n",
    "\n",
    "# Combine them into a single dataframe\n",
    "one_hot_encoded_f = pd.concat([deck, sex, port, class_group, age_group], axis=1)\n",
    "\n",
    "# Combine with X_train\n",
    "X_train = pd.concat([X_train.drop(columns=[\"Sex\", \"Cabin\", \"Embarked\", \"class_group\", \"age_group\"]), one_hot_encoded_f], axis=1)\n",
    "\n",
    "# Remove PassengerId and Survived columns\n",
    "X_train = X_train.drop(columns=[\"Survived\", \"PassengerId\", \"Name\", \"Ticket\"]) #Removing ticket and name, I don't believe it has any relevance\n",
    "\n",
    "# Lets create one-hot encoding for some columns for val_dataset \n",
    "deck_val = pd.get_dummies(X_val.Cabin.str.strip().str[0], prefix=\"Deck\", dummy_na=True, dtype=\"uint8\")\n",
    "sex_val = pd.get_dummies(X_val.Sex, prefix=\"Sex\", dummy_na=True, dtype=\"uint8\")\n",
    "port_val = pd.get_dummies(X_val.Embarked, prefix=\"port\", dummy_na=True, dtype=\"uint8\")\n",
    "class_group_val = pd.get_dummies(X_val.class_group, prefix=\"class\", dummy_na=True, dtype=\"uint8\")\n",
    "age_group_val = pd.get_dummies(X_val.age_group, prefix=\"age\", dummy_na=True, dtype=\"uint8\")\n",
    "\n",
    "one_hot_encoded_val_f = pd.concat([deck_val, sex_val, port_val, class_group_val, age_group_val], axis=1)\n",
    "\n",
    "# Combine with X_val\n",
    "X_val = pd.concat([X_val.drop(columns=[\"Sex\", \"Cabin\", \"Embarked\", \"class_group\", \"age_group\"]), one_hot_encoded_val_f], axis=1)\n",
    "\n",
    "# Remove columns from validation dataset\n",
    "X_val = X_val.drop(columns=[\"Survived\", \"PassengerId\", \"Name\", \"Ticket\"]) #Removing ticket and name, I don't believe it has any relevance\n",
    "\n",
    "# Ensure dimensions match between test & val, if not add correct columns\n",
    "missing_val_cols = [train_col for train_col in X_train.columns if train_col not in X_val.columns]\n",
    "missing_train_cols = [val_col for val_col in X_val.columns if val_col not in X_train.columns]\n",
    "\n",
    "# Add missing val cols\n",
    "for col in missing_val_cols:\n",
    "    X_val[col] = 0 # Only cols that will be missing after all transformations have been completed are the one-hot encoded features\n",
    "\n",
    "for col in missing_train_cols:\n",
    "    X_train[col] = 0 # Only cols that will be missing after all transformations have been completed are the one-hot encoded features\n",
    "\n",
    "# Remove any one-hot enconded column with the word NaN in it.\n",
    "for col in X_train.columns:\n",
    "    if 'nan' in col.lower():\n",
    "        X_train.drop(columns=[col], axis=1, inplace=True)\n",
    "\n",
    "for col in X_val.columns:\n",
    "    if 'nan' in col.lower():\n",
    "        X_val.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Ensure all dimensions match\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13cedf0-16c1-4073-97e5-c613801807ac",
   "metadata": {},
   "source": [
    "# Classifier (NN)\n",
    "- We will now build and train the Neural Network model (NN) that will predict which passengers survived and which didn't.\n",
    "- We will start by creating the architecture, for this model we will be utilizing Dense layers with relu activations for hidden layers and sigmoid for the output layer.\n",
    "- For the loss function, we will use the cross entropy function.\n",
    "- Finally, we will use matplotlib for graphing the train vs val curve, scatter plots for visualizing predictions vs actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "c73f9797-bb33-4dff-8477-ccd4c3962392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5974 - loss: 0.9230 - val_accuracy: 0.6387 - val_loss: 0.9427 - learning_rate: 5.0000e-04\n",
      "Epoch 2/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.8707 - val_accuracy: 0.6359 - val_loss: 0.8884 - learning_rate: 5.0000e-04\n",
      "Epoch 3/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.8272 - val_accuracy: 0.6443 - val_loss: 0.8415 - learning_rate: 5.0000e-04\n",
      "Epoch 4/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.7919 - val_accuracy: 0.6555 - val_loss: 0.8009 - learning_rate: 5.0000e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.7597 - val_accuracy: 0.6583 - val_loss: 0.7697 - learning_rate: 5.0000e-04\n",
      "Epoch 6/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6292 - loss: 0.7338 - val_accuracy: 0.6639 - val_loss: 0.7403 - learning_rate: 5.0000e-04\n",
      "Epoch 7/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 0.7116 - val_accuracy: 0.6639 - val_loss: 0.7135 - learning_rate: 5.0000e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6386 - loss: 0.6918 - val_accuracy: 0.6723 - val_loss: 0.6905 - learning_rate: 5.0000e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6386 - loss: 0.6739 - val_accuracy: 0.6751 - val_loss: 0.6700 - learning_rate: 5.0000e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.6580 - val_accuracy: 0.6947 - val_loss: 0.6486 - learning_rate: 5.0000e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6742 - loss: 0.6421 - val_accuracy: 0.6975 - val_loss: 0.6307 - learning_rate: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.6287 - val_accuracy: 0.7003 - val_loss: 0.6131 - learning_rate: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6835 - loss: 0.6170 - val_accuracy: 0.7199 - val_loss: 0.5981 - learning_rate: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6929 - loss: 0.6066 - val_accuracy: 0.7367 - val_loss: 0.5845 - learning_rate: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.5974 - val_accuracy: 0.7507 - val_loss: 0.5724 - learning_rate: 5.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7079 - loss: 0.5890 - val_accuracy: 0.7563 - val_loss: 0.5624 - learning_rate: 5.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.5816 - val_accuracy: 0.7647 - val_loss: 0.5541 - learning_rate: 5.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5752 - val_accuracy: 0.7675 - val_loss: 0.5474 - learning_rate: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.5696 - val_accuracy: 0.7787 - val_loss: 0.5406 - learning_rate: 5.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5641 - val_accuracy: 0.7787 - val_loss: 0.5350 - learning_rate: 5.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5592 - val_accuracy: 0.7787 - val_loss: 0.5296 - learning_rate: 5.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5547 - val_accuracy: 0.7815 - val_loss: 0.5246 - learning_rate: 5.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5506 - val_accuracy: 0.7927 - val_loss: 0.5202 - learning_rate: 5.0000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.5468 - val_accuracy: 0.7955 - val_loss: 0.5160 - learning_rate: 5.0000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.5428 - val_accuracy: 0.7955 - val_loss: 0.5124 - learning_rate: 5.0000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7584 - loss: 0.5391 - val_accuracy: 0.8011 - val_loss: 0.5091 - learning_rate: 5.0000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.5359 - val_accuracy: 0.7927 - val_loss: 0.5058 - learning_rate: 5.0000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.5323 - val_accuracy: 0.8095 - val_loss: 0.5027 - learning_rate: 5.0000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.5290 - val_accuracy: 0.8095 - val_loss: 0.5005 - learning_rate: 5.0000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.5260 - val_accuracy: 0.8095 - val_loss: 0.4976 - learning_rate: 5.0000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.5226 - val_accuracy: 0.8095 - val_loss: 0.4953 - learning_rate: 5.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.5196 - val_accuracy: 0.8095 - val_loss: 0.4931 - learning_rate: 5.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.5167 - val_accuracy: 0.8095 - val_loss: 0.4905 - learning_rate: 5.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.5131 - val_accuracy: 0.8095 - val_loss: 0.4882 - learning_rate: 5.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.5100 - val_accuracy: 0.8123 - val_loss: 0.4857 - learning_rate: 5.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.5069 - val_accuracy: 0.8151 - val_loss: 0.4838 - learning_rate: 5.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.5040 - val_accuracy: 0.8151 - val_loss: 0.4815 - learning_rate: 5.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.5011 - val_accuracy: 0.8123 - val_loss: 0.4798 - learning_rate: 5.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4982 - val_accuracy: 0.8151 - val_loss: 0.4777 - learning_rate: 5.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4952 - val_accuracy: 0.8123 - val_loss: 0.4766 - learning_rate: 5.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4923 - val_accuracy: 0.8123 - val_loss: 0.4746 - learning_rate: 5.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4898 - val_accuracy: 0.8123 - val_loss: 0.4726 - learning_rate: 5.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4868 - val_accuracy: 0.8123 - val_loss: 0.4711 - learning_rate: 5.0000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4844 - val_accuracy: 0.8151 - val_loss: 0.4697 - learning_rate: 5.0000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4814 - val_accuracy: 0.8123 - val_loss: 0.4685 - learning_rate: 5.0000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4788 - val_accuracy: 0.8095 - val_loss: 0.4671 - learning_rate: 5.0000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4763 - val_accuracy: 0.8095 - val_loss: 0.4653 - learning_rate: 5.0000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.4737 - val_accuracy: 0.8095 - val_loss: 0.4645 - learning_rate: 5.0000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4711 - val_accuracy: 0.8095 - val_loss: 0.4634 - learning_rate: 5.0000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4695 - val_accuracy: 0.8039 - val_loss: 0.4619 - learning_rate: 5.0000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4664 - val_accuracy: 0.8039 - val_loss: 0.4606 - learning_rate: 5.0000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4642 - val_accuracy: 0.8039 - val_loss: 0.4599 - learning_rate: 5.0000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4624 - val_accuracy: 0.8067 - val_loss: 0.4590 - learning_rate: 5.0000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4605 - val_accuracy: 0.8067 - val_loss: 0.4585 - learning_rate: 5.0000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4587 - val_accuracy: 0.8095 - val_loss: 0.4576 - learning_rate: 5.0000e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4567 - val_accuracy: 0.8095 - val_loss: 0.4570 - learning_rate: 5.0000e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4553 - val_accuracy: 0.8123 - val_loss: 0.4561 - learning_rate: 5.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4538 - val_accuracy: 0.8095 - val_loss: 0.4561 - learning_rate: 5.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4521 - val_accuracy: 0.8123 - val_loss: 0.4555 - learning_rate: 5.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4513 - val_accuracy: 0.8151 - val_loss: 0.4555 - learning_rate: 5.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4498 - val_accuracy: 0.8123 - val_loss: 0.4547 - learning_rate: 5.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4484 - val_accuracy: 0.8067 - val_loss: 0.4549 - learning_rate: 5.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4471 - val_accuracy: 0.8151 - val_loss: 0.4543 - learning_rate: 5.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4460 - val_accuracy: 0.8123 - val_loss: 0.4543 - learning_rate: 5.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4449 - val_accuracy: 0.8123 - val_loss: 0.4537 - learning_rate: 5.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4440 - val_accuracy: 0.8123 - val_loss: 0.4535 - learning_rate: 5.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4433 - val_accuracy: 0.8151 - val_loss: 0.4534 - learning_rate: 5.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4424 - val_accuracy: 0.8123 - val_loss: 0.4535 - learning_rate: 5.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4415 - val_accuracy: 0.8095 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.4404 - val_accuracy: 0.8095 - val_loss: 0.4530 - learning_rate: 5.0000e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4398 - val_accuracy: 0.8095 - val_loss: 0.4530 - learning_rate: 5.0000e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4391 - val_accuracy: 0.8095 - val_loss: 0.4528 - learning_rate: 5.0000e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4383 - val_accuracy: 0.8095 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4377 - val_accuracy: 0.8095 - val_loss: 0.4536 - learning_rate: 5.0000e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4370 - val_accuracy: 0.8095 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4360 - val_accuracy: 0.8095 - val_loss: 0.4530 - learning_rate: 5.0000e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4356 - val_accuracy: 0.8095 - val_loss: 0.4533 - learning_rate: 5.0000e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4350 - val_accuracy: 0.8095 - val_loss: 0.4530 - learning_rate: 5.0000e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4346 - val_accuracy: 0.8095 - val_loss: 0.4528 - learning_rate: 5.0000e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4337 - val_accuracy: 0.8095 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4332 - val_accuracy: 0.8095 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4330 - val_accuracy: 0.8123 - val_loss: 0.4526 - learning_rate: 5.0000e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4321 - val_accuracy: 0.8123 - val_loss: 0.4528 - learning_rate: 5.0000e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4315 - val_accuracy: 0.8095 - val_loss: 0.4530 - learning_rate: 5.0000e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4314 - val_accuracy: 0.8123 - val_loss: 0.4528 - learning_rate: 5.0000e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4307 - val_accuracy: 0.8123 - val_loss: 0.4526 - learning_rate: 5.0000e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4303 - val_accuracy: 0.8123 - val_loss: 0.4534 - learning_rate: 5.0000e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4303 - val_accuracy: 0.8095 - val_loss: 0.4535 - learning_rate: 5.0000e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4292 - val_accuracy: 0.8095 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4287 - val_accuracy: 0.8095 - val_loss: 0.4537 - learning_rate: 5.0000e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4285 - val_accuracy: 0.8095 - val_loss: 0.4538 - learning_rate: 5.0000e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4279 - val_accuracy: 0.8095 - val_loss: 0.4532 - learning_rate: 5.0000e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4275 - val_accuracy: 0.8067 - val_loss: 0.4538 - learning_rate: 5.0000e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4269 - val_accuracy: 0.8067 - val_loss: 0.4541 - learning_rate: 5.0000e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4266 - val_accuracy: 0.8067 - val_loss: 0.4543 - learning_rate: 5.0000e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4262 - val_accuracy: 0.8067 - val_loss: 0.4544 - learning_rate: 5.0000e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4262 - val_accuracy: 0.8067 - val_loss: 0.4554 - learning_rate: 5.0000e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4250 - val_accuracy: 0.8067 - val_loss: 0.4552 - learning_rate: 2.5000e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.4250 - val_accuracy: 0.8067 - val_loss: 0.4549 - learning_rate: 2.5000e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4247 - val_accuracy: 0.8067 - val_loss: 0.4551 - learning_rate: 2.5000e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4244 - val_accuracy: 0.8067 - val_loss: 0.4550 - learning_rate: 2.5000e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4241 - val_accuracy: 0.8067 - val_loss: 0.4550 - learning_rate: 2.5000e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4239 - val_accuracy: 0.8067 - val_loss: 0.4551 - learning_rate: 2.5000e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4237 - val_accuracy: 0.8067 - val_loss: 0.4549 - learning_rate: 2.5000e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4236 - val_accuracy: 0.8067 - val_loss: 0.4553 - learning_rate: 2.5000e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4233 - val_accuracy: 0.8067 - val_loss: 0.4553 - learning_rate: 2.5000e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4232 - val_accuracy: 0.8067 - val_loss: 0.4554 - learning_rate: 2.5000e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4229 - val_accuracy: 0.8067 - val_loss: 0.4555 - learning_rate: 2.5000e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4228 - val_accuracy: 0.8067 - val_loss: 0.4557 - learning_rate: 2.5000e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4227 - val_accuracy: 0.8067 - val_loss: 0.4558 - learning_rate: 2.5000e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4227 - val_accuracy: 0.8067 - val_loss: 0.4558 - learning_rate: 2.5000e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4223 - val_accuracy: 0.8067 - val_loss: 0.4556 - learning_rate: 2.5000e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4220 - val_accuracy: 0.8067 - val_loss: 0.4557 - learning_rate: 1.2500e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4219 - val_accuracy: 0.8067 - val_loss: 0.4557 - learning_rate: 1.2500e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4218 - val_accuracy: 0.8067 - val_loss: 0.4556 - learning_rate: 1.2500e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4217 - val_accuracy: 0.8067 - val_loss: 0.4556 - learning_rate: 1.2500e-04\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "# Ensure order of columns are the same for X_train and X_val before normalizing\n",
    "X_train.drop(columns=[\"Age\", \"survival_rate\", \"group_size\"], inplace=True)\n",
    "X_val.drop(columns=[\"Age\", \"survival_rate\", \"group_size\"], inplace=True)\n",
    "\n",
    "X_val = X_val.reindex(columns=X_train.columns)\n",
    "\n",
    "# lets normalize all features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(16, activation='relu', name='layer1', kernel_regularizer=L2(1e-3)),\n",
    "        Dense(8, activation='relu', name='layer2', kernel_regularizer=L2(1e-3)),\n",
    "        Dense(1, activation='sigmoid', name='output')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure the optimizer, loss function and metrics to be used\n",
    "model.compile(optimizer=Adam(0.0005), loss=BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "# Drop PassengerId cols\n",
    "if \"PassengerId\" in y_train.columns:\n",
    "    y_train = y_train.drop(columns=[\"PassengerId\"])\n",
    "\n",
    "if \"PassengerId\" in y_val.columns:\n",
    "    y_val = y_val.drop(columns=[\"PassengerId\"])\n",
    "\n",
    "# Create early stopping and lr reducer callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor=\"val_loss\", patience=15, factor=0.5, verbose=0, min_lr=1e-6)\n",
    "\n",
    "# Fit training data\n",
    "model.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), batch_size=32, epochs=1000, verbose=1, callbacks=[early_stopping, lr_reducer])\n",
    "\n",
    "# Get the probabilities from the model using the X_train dataset\n",
    "train_probs = model.predict(X_train_scaled).reshape(-1)\n",
    "\n",
    "# Apply threshold at 0.5\n",
    "y_pred = (train_probs > 0.5).astype(int)\n",
    "\n",
    "y_pred = pd.DataFrame(data=y_pred, columns=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ce6b7-90a4-45a8-9d77-43f366d99ea8",
   "metadata": {},
   "source": [
    "## Prediction vs Actuals Analysis\n",
    "- Lets inspect the passengers the model predicted as Survived vs the Actual values.\n",
    "- Start by creating a Dataframe containing the Test features, labels, model probability and the predictions\n",
    "- We will then extract the accuracy of the predictions by comparing preds vs total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "03219299-bd00-4d98-8427-cbf899a61d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Survived_pred</th>\n",
       "      <th>Survived_probs</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068297</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49.5042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132496</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Survived_pred  Survived_probs  Pclass  Sex_female  Sex_male  \\\n",
       "0         0              0        0.136018       3           0         1   \n",
       "1         0              0        0.068297       3           0         1   \n",
       "2         1              1        0.955249       1           1         0   \n",
       "3         0              0        0.132496       3           0         1   \n",
       "4         1              1        0.953745       1           1         0   \n",
       "\n",
       "      Fare  \n",
       "0   8.0500  \n",
       "1  29.1250  \n",
       "2  49.5042  \n",
       "3   6.4958  \n",
       "4  27.7208  "
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert probs to 2D array\n",
    "train_probs = train_probs.reshape(-1, 1)\n",
    "\n",
    "# Rename prediction column\n",
    "y_pred = y_pred.rename(columns={\"Survived\": \"Survived_pred\"})\n",
    "\n",
    "# Create dataframe for easier comparision\n",
    "train_probs = pd.DataFrame(train_probs, columns=[\"Survived_probs\"])\n",
    "preds_vs_actuals = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True), train_probs.reset_index(drop=True), y_pred.reset_index(drop=True)], axis=1)\n",
    "\n",
    "preds_vs_actuals.loc[:, [\"Survived\", \"Survived_pred\", \"Survived_probs\", \"Pclass\", \"Sex_female\", \"Sex_male\", \"Fare\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "cc408e32-f556-412c-847a-0045b2b97a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived mismatches: 76\n",
      "Not Survived mismatches: 19\n",
      "Survived matches: 136\n",
      "Not Survived matches: 303\n",
      "Prediction accuracy: 82.20973782771536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Survived_pred</th>\n",
       "      <th>Survived_probs</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.8583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204570</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.401913</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.8500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Survived_pred  Survived_probs  Pclass  Sex_female  Sex_male  \\\n",
       "6          1              0        0.434091       1           0         1   \n",
       "14         1              0        0.136018       3           0         1   \n",
       "19         1              0        0.204570       3           0         1   \n",
       "47         1              0        0.423245       1           0         1   \n",
       "48         1              0        0.401913       3           1         0   \n",
       "\n",
       "       Fare  \n",
       "6   81.8583  \n",
       "14   8.0500  \n",
       "19  15.9000  \n",
       "47  91.0792  \n",
       "48  15.8500  "
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract mismatches between preds and actuals\n",
    "survived = preds_vs_actuals[(preds_vs_actuals.Survived > 0) & (preds_vs_actuals.Survived_pred < 1)]\n",
    "not_survived = preds_vs_actuals[(preds_vs_actuals.Survived < 1) & (preds_vs_actuals.Survived_pred > 0)]\n",
    "\n",
    "# Extract matches between preds and actuals\n",
    "matching_survived = preds_vs_actuals[(preds_vs_actuals.Survived > 0) & (preds_vs_actuals.Survived_pred > 0)]\n",
    "matching_not_survived = preds_vs_actuals[(preds_vs_actuals.Survived < 1) & (preds_vs_actuals.Survived_pred < 1)]\n",
    "\n",
    "\n",
    "print(f\"Survived mismatches: {survived.shape[0]}\")\n",
    "print(f\"Not Survived mismatches: {not_survived.shape[0]}\")\n",
    "print(f\"Survived matches: {matching_survived.shape[0]}\")\n",
    "print(f\"Not Survived matches: {matching_not_survived.shape[0]}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "matching_total = matching_survived.shape[0] + matching_not_survived.shape[0]\n",
    "accuracy = matching_total / preds_vs_actuals.shape[0]\n",
    "print(f\"Prediction accuracy: {accuracy*100}\")\n",
    "\n",
    "survived.loc[:, [\"Survived\", \"Survived_pred\", \"Survived_probs\", \"Pclass\", \"Sex_female\", \"Sex_male\", \"Fare\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b0f24-ee5a-4477-ba70-27a056c929cd",
   "metadata": {},
   "source": [
    "## Train Prediction Plot\n",
    "- Lets plot the train predictions vs actuals to help us visualize if our threshold is good or if a different threshold might be beneficial.\n",
    "- We will use matplotlib to create a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f01f9458-3e20-4b46-b8b0-2b3493e62551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figsize and scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_train.Survived.to_numpy(), train_probs, alpha=0.5)\n",
    "\n",
    "# Threshold line\n",
    "plt.axhline(y=0.5, color=\"r\", linestyle=\"--\", label=f\"Threshold = {0.5}\")\n",
    "\n",
    "plt.title(\"Predicted Probabilities vs Actuals\")\n",
    "plt.xlabel(\"Actual (0 or 1)\")\n",
    "plt.ylabel(\"Predicted Probability\")\n",
    "plt.xticks([0,1])\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deea97d-bf28-42b5-acff-635bddb46797",
   "metadata": {},
   "source": [
    "## Train vs Val Curve\n",
    "- Lets plot the Train vs Val curve to visualize and analyze overfitting vs undefitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "5720354f-f710-4cf6-8918-1aaf96b90e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(model.history.history[\"loss\"], label=\"Training Loss\", color=\"blue\")\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"Validation Loss\", color=\"orange\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a06c8-0909-4f61-b53a-68702e2f793a",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "- Now lets create our test dataset to generate the predictions we will submit.\n",
    "- Start by importing the test.csv into a pandas dataframe.\n",
    "- We will then create the class_group and age_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "59f9d1de-09f2-44ed-9582-48741f209127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>class_group</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Lower</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Middle</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked class_group age_group  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q       Lower    middle  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S       Lower    middle  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q      Middle       old  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S       Lower     young  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S       Lower     young  "
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../titanic_data/test.csv\")\n",
    "\n",
    "# Create the class_group and the age_group engineered feature.\n",
    "df_test[\"class_group\"] = df_test.Pclass.map({1: \"Upper\", 2: \"Middle\", 3: \"Lower\"})\n",
    "df_test[\"age_group\"] = pd.cut(df_test.Age, bins=[-np.inf, 30, 60, np.inf], labels=[\"young\", \"middle\", \"old\"], right=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68f90b-2a39-4c84-b816-fbc5e7d01075",
   "metadata": {},
   "source": [
    "## Test NaN Values\n",
    "- We need to fill all NaN values just like we did in our train and val dataset.\n",
    "- We will do so in the following order: embarked, age, cabin, others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "8c2687a5-9bca-41e7-a262-b644714abfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "class_group      0\n",
      "age_group       86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lets fill Embarked utilizing the top Embarkment/port observed by class and gender \n",
    "embarked_by_class_gender = ( \n",
    "    df_test.groupby([\"class_group\", \"Sex\", \"Embarked\"], observed=True)\n",
    "    .size() \n",
    "    .reset_index(name='n') \n",
    ") \n",
    "\n",
    "# Extract top Embarkments/ports\n",
    "top_embarkments = ( \n",
    "    embarked_by_class_gender \n",
    "    .sort_values([\"class_group\", \"Sex\", \"n\", \"Embarked\"], ascending=[True, True, False, True]) \n",
    "    .drop_duplicates(subset=[\"class_group\", \"Sex\"], keep=\"first\") \n",
    "    .rename(columns={'Embarked': 'top_embarked', 'n': 'top_count'})\n",
    "    .reset_index(drop=True) \n",
    ") \n",
    "\n",
    "X_test = df_test.merge(top_embarkments, on=[\"class_group\", \"Sex\"], how=\"left\") \n",
    "X_test.Embarked = X_test.Embarked.fillna(X_test.top_embarked) \n",
    "X_test.drop(columns=[\"top_count\", \"top_embarked\"], inplace=True) \n",
    "\n",
    "print(X_test.isna().sum()) # Embarked should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "0f9357de-c269-4f6c-abca-02c49e4f0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "class_group      0\n",
      "age_group        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lets fill Age utilizing the top age observed by class, gender, and embarkment \n",
    "age_by_class_gender = ( \n",
    "    X_test.groupby([\"class_group\", \"Sex\", \"Embarked\", \"Age\"], observed=True)\n",
    "    .size()\n",
    "    .reset_index(name='n') \n",
    ") \n",
    "\n",
    "# Extract the top ages\n",
    "top_ages = ( \n",
    "    age_by_class_gender\n",
    "    .sort_values([\"class_group\", \"Sex\", \"Embarked\", \"Age\", \"n\"], ascending=[True, True, True, True, False]) \n",
    "    .drop_duplicates(subset=[\"class_group\", \"Sex\", \"Embarked\"], keep=\"first\") \n",
    "    .rename(columns={\"Age\": \"top_age\", \"n\": \"top_count\"}) \n",
    "    .reset_index(drop=True) \n",
    ") \n",
    "\n",
    "# Fill Age NaNs\n",
    "X_test = X_test.merge(top_ages, on=[\"class_group\", \"Sex\", \"Embarked\"], how=\"left\") \n",
    "X_test.Age = X_test.Age.fillna(X_test.top_age) \n",
    "X_test.drop(columns=[\"top_count\", \"top_age\"], inplace=True) \n",
    "\n",
    "# Lets reapply the Age bins to remove NaNs from age_group as well \n",
    "X_test[\"age_group\"] = pd.cut( \n",
    "    X_test.Age, \n",
    "    bins = [-np.inf, 30, 60, np.inf], \n",
    "    labels = [\"young\", \"middle\", \"old\"], \n",
    "    right=True\n",
    ") \n",
    "\n",
    "print(X_test.isna().sum()) # Age and age_group should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "81303e5c-0acf-4d6a-9857-6cbbca4d2de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           1\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "class_group    0\n",
      "age_group      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The assignment of a cabin to a passenger was most likely affected by the passenger's socio-economic class and age\n",
    "# Lets try to find a pattern, lets look group cabin by socio-economic class\n",
    "# We will only use the first letter of the cabin\n",
    "X_test.Cabin = X_test.Cabin.str.strip().str[0]\n",
    "\n",
    "#Lets extract passangers avg per Cabin, grouped by socio-economic class, age group and sex\n",
    "cabin_by_class = (\n",
    "    X_test.groupby([\"class_group\", \"age_group\", \"Sex\", \"Cabin\"], observed=True, dropna=False)\n",
    "    .size()\n",
    "    .reset_index(name='n')\n",
    ")\n",
    "\n",
    "keys = ['class_group', 'age_group', 'Sex']\n",
    "valid_cabins = cabin_by_class[cabin_by_class['Cabin'].notna()].copy()\n",
    "\n",
    "# Extract top cabins per group\n",
    "top_cabins_per_group = (\n",
    "    valid_cabins\n",
    "      .sort_values(keys + ['n', 'Cabin'], ascending=[True, True, True, False, True])\n",
    "      .drop_duplicates(subset=keys, keep='first')\n",
    "      .rename(columns={'Cabin': 'top_cabin', 'n': 'top_count'})\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Fall back in case all NaNs cannot be filled by top_cabins_per_group\n",
    "top_cabin_per_class = (\n",
    "    valid_cabins\n",
    "    .sort_values(\"class_group\", ascending=[True])\n",
    "    .drop_duplicates(subset=[\"class_group\"], keep=\"first\")\n",
    "    .rename(columns={'Cabin': 'top_cabin', 'n': 'top_count'})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Fill NaN Cabin with the group's most common cabin\n",
    "X_test = X_test.merge(top_cabins_per_group[['class_group', 'age_group', 'Sex', 'top_cabin']], on=keys, how='left')\n",
    "X_test['Cabin'] = X['Cabin'].fillna(X_test['top_cabin'])\n",
    "X_test.drop(columns=[\"top_cabin\"], errors='ignore', inplace=True)\n",
    "\n",
    "# Fallback in case there are still NaNs for Cabins\n",
    "if X_test.Cabin.isna().sum() > 0:\n",
    "    cabin_by_class = (\n",
    "        X_test.groupby([\"class_group\", \"Cabin\"], observed=True, dropna=True)\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "    )\n",
    "\n",
    "    X_test = X_test.merge(top_cabin_per_class[['class_group', 'top_cabin']], on='class_group', how='left')\n",
    "    X_test['Cabin'] = X_test['Cabin'].fillna(X_test['top_cabin'])\n",
    "\n",
    "X_test.drop(columns=[\"top_cabin\"], errors='ignore', inplace=True)\n",
    "\n",
    "X_test.head(10)\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "5c811857-7898-484a-946a-bf04a344e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "class_group    0\n",
      "age_group      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lets fill fare utilizing the top fare observed by class\n",
    "fare_by_class= ( \n",
    "    X_test.groupby([\"class_group\", \"Fare\"], observed=True)\n",
    "    .size() \n",
    "    .reset_index(name='n') \n",
    ") \n",
    "\n",
    "# Extract top fares\n",
    "top_fares = ( \n",
    "    fare_by_class \n",
    "    .sort_values([\"class_group\", \"n\", \"Fare\"], ascending=[True, False, True]) \n",
    "    .drop_duplicates(subset=[\"class_group\"], keep=\"first\") \n",
    "    .rename(columns={'Fare': 'top_fare', 'n': 'top_count'})\n",
    "    .reset_index(drop=True) \n",
    ") \n",
    "\n",
    "# Fill all NaNs\n",
    "X_test = X_test.merge(top_fares, on=[\"class_group\"], how=\"left\") \n",
    "X_test.Fare = X_test.Fare.fillna(X_test.top_fare) \n",
    "X_test.drop(columns=[\"top_count\", \"top_fare\"], inplace=True) \n",
    "\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3828a1c-ff03-41f5-bbbc-4237babeb8ac",
   "metadata": {},
   "source": [
    "## Test Dataset Transformation\n",
    "- Lets finalize the Test dataset by creating the appropriate categorical columns as one-hot encoded columns.\n",
    "- We will also scale the Test feature dataset with z-score normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "6145b2f1-03f7-4683-a129-ce54a9996f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass          0\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Fare            0\n",
      "Deck_A          0\n",
      "Deck_B          0\n",
      "Deck_C          0\n",
      "Deck_D          0\n",
      "Deck_E          0\n",
      "Deck_F          0\n",
      "Deck_G          0\n",
      "Sex_female      0\n",
      "Sex_male        0\n",
      "port_C          0\n",
      "port_Q          0\n",
      "port_S          0\n",
      "class_Lower     0\n",
      "class_Middle    0\n",
      "class_Upper     0\n",
      "age_young       0\n",
      "age_middle      0\n",
      "age_old         0\n",
      "Deck_T          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lets create one-hot encoding for some columns for test_dataset \n",
    "deck_test = pd.get_dummies(X_test.Cabin.str.strip().str[0], prefix=\"Deck\", dummy_na=True, dtype=\"uint8\")\n",
    "sex_test = pd.get_dummies(X_test.Sex, prefix=\"Sex\", dummy_na=True, dtype=\"uint8\")\n",
    "port_test = pd.get_dummies(X_test.Embarked, prefix=\"port\", dummy_na=True, dtype=\"uint8\")\n",
    "class_group_test = pd.get_dummies(X_test.class_group, prefix=\"class\", dummy_na=True, dtype=\"uint8\")\n",
    "age_group_test = pd.get_dummies(X_test.age_group, prefix=\"age\", dummy_na=True, dtype=\"uint8\")\n",
    "\n",
    "one_hot_encoded_test_f = pd.concat([deck_test, sex_test, port_test, class_group_test, age_group_test], axis=1)\n",
    "\n",
    "missing_test_cols = [test_col for test_col in X_test.columns if test_col not in X_train.columns]\n",
    "\n",
    "# Combine with X_test\n",
    "X_test = pd.concat([X_test.drop(columns=[\"Sex\", \"Cabin\", \"Embarked\", \"class_group\", \"age_group\"]), one_hot_encoded_test_f], axis=1)\n",
    "\n",
    "# Add missing test cols\n",
    "for col in missing_test_cols:\n",
    "    X_test[col] = 0 # Only cols that will be missing after all transformations have been completed are the one-hot encoded features\n",
    "\n",
    "# Remove any one-hot encoded columns that have NaN in their name.\n",
    "for col in X_test.columns:\n",
    "    if 'nan' in col.lower():\n",
    "        X_test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# I'm eliminating name and ticket as I believe these do not hold any relevance to a passenger's survival\n",
    "X_test.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"], inplace=True)\n",
    "X_test = X_test.reindex(columns=X_train.columns)\n",
    "\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "ecb8f211-ddfe-498c-be9e-fd02c5ad2083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    }
   ],
   "source": [
    "# Normalize the test feature dataset with z-score.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_probs = model.predict(X_test_scaled).reshape(-1)\n",
    "\n",
    "# Apply threshold at 0.5\n",
    "test_pred = (test_probs > 0.5).astype(int)\n",
    "\n",
    "# Create submission dataset and export results as csv.\n",
    "y_pred = pd.DataFrame(data=test_pred, columns=[\"Survived\"])\n",
    "\n",
    "X_test_passengers = df_test[[\"PassengerId\"]]\n",
    "\n",
    "test_preds = pd.concat([X_test_passengers[\"PassengerId\"], y_pred], axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "test_preds.to_csv(\"../titanic_data/preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee6f74-5557-4cf1-8e3f-f7432db85feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
